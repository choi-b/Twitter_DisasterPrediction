{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#torch/transformers\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AdamW, BertConfig, BertModel, BertTokenizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#nltk\n",
    "from nltk.stem.porter import PorterStemmer #for stemming\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re #regex for data cleaning later\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only work with text/target columns\n",
    "train = train[[\"text\",\"target\"]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing/Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train into X and y\n",
    "X_train = train[\"text\"].values\n",
    "y_train = train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model, do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: this is a sample text\n",
      "   Tokens: ['this', 'is', 'a', 'sample', 'text']\n",
      "Token IDs: [1142, 1110, 170, 6876, 3087]\n"
     ]
    }
   ],
   "source": [
    "sample_text = 'this is a sample text'\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_text}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "\n",
    "for text in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    lens.append(encoded_dict['input_ids'].size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length mean:  35.49362931827138\n",
      "text length median:  36.0\n",
      "text length standard deviation:  13.213784110010584\n",
      "suitable sequence length:  61.921197538292546\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFPCAYAAADjktLUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZglZXn38e8PUEBAZRPZxyii4II6YhJNBFdc0cQFYwyu6Bv3mCguicRXDBrFJWoUIpsruOOrUcEFQkSGEVE2CSgjjGwDgoAiynC/f1R1PLbdPaer+5zqnv5+rquuPqeqnnrueqrO6fs8taWqkCRJUn826DsASZKkpc6ETJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImaV4k2T3J95PcmOQV87C8ZUkqyUbzEV+H+v8syYXzuLxjkrx1vpY3ZJ2rkjyqY9lKco/5jknS1EzIpCG0/9huTnLTwLBD33EtMK8Fvl1VW1TV+wYnJDlvoN3WJvn1wPs39BTvjKrqv6pq9y5lkzw3yWnzHdNi0K772oHte0mSo5PccxbLGEvy2keSLE3HhEwa3pOqavOB4fLBiX315CwguwLnTTWhqvacaDfgv4CXDbTj28Yapcbh9HZb3wl4FHAz8L0k9+k3LGnhMiGT5qA9rPPSJBcBF7Xjnpjk7CTXJ/lOkvsNzP+AJGe1h/WOT/KpiV/oU/WqDB42SrJxkncmuTTJVUk+lGTTdto+SVYneU2Sq5NckeR5A8vZNMm7kvw0yS+SnNaO+3KSl0+q84dJnjLN+j657e26Psm3k9y7Hf9NYF/g/W2vyFC9IUk2SPKmNq6rkxyX5E7TzPuXbU/lfdpyByf5cZJrk5yQZKt2volDnQe2bXVNkjcOLGfvJCuT3NC24+HT1LdPktUD71cl+fu2fX7Rbr9Npih3b+BDwJ+0bXH9wOQt2za/MckZSe4+UO5eSU5K8vMkFyZ5xjRx7ZvknIH3JydZMfD+tEnbb6/pYk7yoiQXt3WemGl6fWfa92ZSVWur6sdV9bfAKcAhA8v8dJIr27hOTbJnO/4g4NnAa9v2+1I7fmJ735jk/CRPHVjWPZKc0i7rmiTHr6tdp6tH6k1VOTg4rGMAVgGPmmJ8AScBWwGbAg8ErgYeAmwIHNiW3Ri4PfBT4NXA7YCnAb8F3tou67nAaVMs/x7t6/cAJ7Z1bQF8CfiXdto+wK3AW9plPx74FbBlO/0DwLeBHdu4/rSN6RnAGQP13R+4Frj9FOt6T+CXwKPbOl4LXDwxb7v8Fw7Rlv87H/D8dhl/BGwOfA74aDttWbv+GwHPa+ebaItXAd8FdmrX48PAJyeVO7LdJvcHbgHu3U4/HXhO+3pz4I+niXMfYPWkfWAFsEO7DS4AXjJN2am25THAz4G923X6OPCpdtpmwGXtem5Esx9dA+w5xbI3oelx2qad90rg8naf2LSdtvW6YgYe0dbxwLYN/w04dbb73jDrPrCtr5r0fou27vcAZ09qq7dOKv/0dj02AJ5Jsy9u3077JPDGdtomwMOGadep6nFw6Guwh0wa3hfanqHrk3xhYPy/VNXPq+pm4EXAh6vqjGp6B46lSQb+uB1uB7ynqn5bVZ8Bzhym4iRpl/3qtq4bgbcBBwzM9lvgLe2yvwLcBOyeZAOaf36vrKqftXF9p6puAb4I7JZkt3YZzwGOr6rfTBHGM4EvV9VJVfVb4J00CcCfDrMO03g2cHhV/aSqbgJeDxyQ3z/8+yrgH4B9quridtyLgTdW1ep2PQ4Bnjap3D9X1c1V9QPgBzSJGTTtdI8k21TVTVX13VnE+76quryqfk6TlOw1y/X9XFWtqKpbaRKyifJPBFZV1dFVdWtVnQV8liZp/z1V9WtgJfDnwHLgh8BpwENp9rGLquraIWJ+NnBUVZ3VtuHraXr1lg3WN+S+N4zLaRK6ifU4qqpuHNh+95+ud7Sd/9PtetxWVcfT9Ejv3U7+Lc0h8x2q6tdVNdHTPHS7Sn0zIZOG95SqunM7DB4Sumzg9a7AawYSt+uBnWl+2e8A/KyqamD+nw5Z97bAHWjOw5lY7lfb8ROubf/RT/gVTQ/QNjS9Bj+evND2n+EJwF+3iduzgI9OE8MOg/FW1W00677jkOuwzmW2rzcCthsY9w/AB6pq9cC4XYHPD7TFBcDaSeWuHHg90RYAL6Dp7ftRkjOTPHEW8U63zLmW3xV4yKT95tnAXadZzik0PXh/3r7+NvDwdjhlyDonb8+baHpHJ2/PYfa9YexI00NIkg2THNYegryBpicPmn11Skn+Jr87FeB64D4D878WCLAizSH157fjZ9uuUm+W+knI0nwYTLAuAw6tqkMnz5Tk4cCOSTKQlO3C7xKlX9L845uYf/CfxjU0h6L2rKqfzTK+a4BfA3en6Sma7FiaJOw04FdVdfo0y7kcuO9AfKFJNmcbz+Rl7jrwfheaQ69X0RyOBHgM8NUkV1bVZ9txlwHPr6r/nrzAyT08k1XVRcCz2gT0L4DPJNm6qn45h/X4g2pmOf9lwClV9egh5z8FeBdwKXAYcB3NIdpbaA5PD+P32j7JZsDW/OH2nMu+N+ipNBd0APwVsD/NCf+raE7+v44mqYJJ7ZdkV5r1eyTNBQNrk5w9MX9VXUnTi0eShwEnJzmVdbfrbLeTNDL2kEnz60jgJUkeksZmSZ6QZAuac5duBV6RZKMkf8HvDrlAkyztmWSv9sTrQyYmtL1RRwLvTnIXgCQ7JnnsugJqyx4FHJ5kh7Z34k+SbNxOPx24jeYf/HS9Y9D0pD0hySOT3A54DU0C8J2hWmZqnwReneRuSTanORR2/KSevvOA/YAPJHlyO+5DwKHtP2qSbJtk/2EqTPLXSbZt22XihPu1c1iHqVwF7JTk9kPO//+AeyZ5TpLbtcOD0140MYXvALvT7D8rquo82t4g4NQh6/wE8Lx2f9uYpu3PqKpVgzPNZd9r97W7Jfk3mh69f24nbUGz71xL8yNk8pW2V9GcVzhhM5rkaU273OfR9JBN1PP0JBMJ/HXtvGtZd7tOrkfqjQmZNI+qaiXNL/X30/xjuJjmJGfa87L+on1/Hc05WZ8bKPs/NCfln0xzfszk+1i9rl3ed9vDPCfT/FMext8D59Ccs/Zz4O38/uf/OJrer4/NsG4XAn9Nc/L3NcCTaG4FMtX5ZsM6iiYJPBW4hKYn7+WTZ2rPA3sicGSSxwHvpTnJ/OtJbqQ5wf8hQ9a5H3Bekpva5RzQnpc1n75Jk0hemeSadc3cnpf1GJrzsi6nOcz4dpoT3qea/5fAWcB5A+1/OvDTqrp6mACr6hvAP9KcU3UFTQ/qdOeFzXbf+5O2fW+gOZx6R+DBVTVxdehxNIdLfwacT7P9Bn0E2GPifM2qOp/mB8PpNEnUfYHB3tEHA2e0dZ5Ic77kJUO06+/VM8P6SCOX3z+dRdI4JTmG5kq+N/Ucx98AB1XVw/qMQ5KWKnvIpCUuyR2AvwWO6DsWSVqqTMikJaw9D2gNzWGgT/QcjiQtWR6ylCRJ6pk9ZJIkST0b2X3IkuxMcyXNXWkuqT+iqt6b5BCaq9DWtLO+ob2rOEleT3PTxrXAK6rqazPVsc0229SyZctGswKSJEnz6Hvf+941VTXlTZVHeWPYW4HXVNVZ7T2YvpfkpHbau6vqnYMzJ9mD5tLkPWnuIH1ykntW1bT3B1q2bBkrV64cUfiSJEnzJ8m0T2cZ2SHLqrqifW7YxD12LmDmR6zsT/Og3Vuq6hKae97sPcP8kiRJ64WxnEPWPsrkAcAZ7aiXJflhkqOSbNmO25Hffybgaub2jDxJkqRFYeQJWfs4lM8Cr6qqG4B/p7kj9F40d4d+18SsUxT/g0tAkxyUZGWSlWvWrJmiiCRJ0uIy0oSsfd7dZ4GPV9XnAKrqqqpaO/B8tInDkqtpHlQ8YSeaR138nqo6oqqWV9Xybbed8rw4SZKkRWVkCVmS0Dwn7IKqOnxg/PYDsz0VOLd9fSJwQJKNk9wN2A1YMar4JEmSFopRXmX5UOA5wDlJzm7HvQF4VpK9aA5HrgJeDFBV5yU5geZBs7cCL53pCktJkqT1xcgSsqo6janPC/vKDGUOBQ4dVUySJEkLkXfqlyRJ6pkJmSRJUs9MyCRJknpmQiZJktSzUV5lOXbLDv7ytNNWHfaEMUYiSZI0PHvIJEmSemZCJkmS1LP16pBlVx7qlCRJfbKHTJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST3z0Ulz4COXJEnSfLCHTJIkqWcmZJIkST0zIZMkSeqZ55D1wHPPJEnSIHvIJEmSemYP2SJiz5okSesne8gkSZJ6ZkImSZLUMxMySZKknnkO2RLguWeSJC1s9pBJkiT1zIRMkiSpZyZkkiRJPTMhkyRJ6pkJmSRJUs9MyCRJknpmQiZJktQzEzJJkqSemZBJkiT1zIRMkiSpZyZkkiRJPTMhkyRJ6pkPF9e0pnsouQ8klyRpftlDJkmS1DN7yDSvputVA3vWJEmajgmZFgQTOUnSUjayhCzJzsBxwF2B24Ajquq9SbYCjgeWAauAZ1TVdW2Z1wMvANYCr6iqr40qPq0fTOQkSeuDUfaQ3Qq8pqrOSrIF8L0kJwHPBb5RVYclORg4GHhdkj2AA4A9gR2Ak5Pcs6rWjjBGLVEmcpKkhWRkCVlVXQFc0b6+MckFwI7A/sA+7WzHAt8GXteO/1RV3QJckuRiYG/g9FHFKM1W10TOBFCSNJOxXGWZZBnwAOAMYLs2WZtI2u7SzrYjcNlAsdXtuMnLOijJyiQr16xZM8qwJUmSxmLkJ/Un2Rz4LPCqqrohybSzTjGu/mBE1RHAEQDLly//g+nS+sSeNUlaGkbaQ5bkdjTJ2Mer6nPt6KuSbN9O3x64uh2/Gth5oPhOwOWjjE+SJGkhGFlClqYr7CPABVV1+MCkE4ED29cHAl8cGH9Ako2T3A3YDVgxqvgkSZIWilEesnwo8BzgnCRnt+PeABwGnJDkBcClwNMBquq8JCcA59NcoflSr7CUJElLwSivsjyNqc8LA3jkNGUOBQ4dVUzSUuHVoJK0uHinfklzZiInSXPjw8UlSZJ6ZkImSZLUMw9ZSuqNhzolqWEPmSRJUs9MyCRJknpmQiZJktQzzyGTtOh47pmk9Y09ZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST0zIZMkSeqZj06StGT4yCVJC5U9ZJIkST0zIZMkSeqZCZkkSVLPPIdMktbBc88kjZo9ZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST3bqO8AJGl9tezgL087bdVhTxhjJJIWOnvIJEmSemZCJkmS1DMTMkmSpJ6ZkEmSJPVsZAlZkqOSXJ3k3IFxhyT5WZKz2+HxA9Nen+TiJBcmeeyo4pIkSVpoRtlDdgyw3xTj311Ve7XDVwCS7AEcAOzZlvlgkg1HGJskSdKCMbKErKpOBX4+5Oz7A5+qqluq6hLgYmDvUcUmSZK0kPRxDtnLkvywPaS5ZTtuR+CygXlWt+P+QJKDkqxMsnLNmjWjjlWSJGnkxp2Q/Ttwd2Av4ArgXe34TDFvTbWAqjqiqpZX1fJtt912NFFKkiSN0VAJWZL7zEdlVXVVVa2tqtuAI/ndYcnVwM4Ds+4EXD4fdUqSJC10wz466UNJbk9zov4nqur6LpUl2b6qrmjfPhWYuALzROATSQ4HdgB2A1Z0qUOSFjsfuSQtPUMlZFX1sCS7Ac8HViZZARxdVSdNVybJJ4F9gG2SrAbeDOyTZC+aw5GrgBe3yz8vyQnA+cCtwEuram3ntZKkJchETlq8hn64eFVdlORNwErgfcADkgR4Q1V9bor5nzXFYj4yw/IPBQ4dNh5JkqT1xbDnkN0vybuBC4BHAE+qqnu3r989wvgkSZLWe8P2kL2f5iT8N1TVzRMjq+ryttdMkiRJHQ2bkD0euHnivK4kGwCbVNWvquqjI4tOkiRpCRj2PmQnA5sOvL9DO06SJElzNGwP2SZVddPEm6q6KckdRhSTJGmMvDpT6t+wPWS/TPLAiTdJHgTcPMP8kiRJGtKwPWSvAj6dZOLu+dsDzxxNSJIkSUvLsDeGPTPJvYDdaZ47+aOq+u1II5MkSVoihr4xLPBgYFlb5gFJqKrjRhKVJGnB63ru2XTlPF9NS9lQCVmSjwJ3B84GJh5pVIAJmSRJ0hwN20O2HNijqmqUwUiSJC1Fw15leS5w11EGIkmStFQN20O2DXB+khXALRMjq+rJI4lKkqQB3itN67thE7JDRhmEJEnSUjbsbS9OSbIrsFtVndzepX/D0YYmSdLc2LOmxWKoc8iSvAj4DPDhdtSOwBdGFZQkSdJSMuxJ/S8FHgrcAFBVFwF3GVVQkiRJS8mwCdktVfWbiTdJNqK5D5kkSZLmaNiE7JQkbwA2TfJo4NPAl0YXliRJ0tIx7FWWBwMvAM4BXgx8BfiPUQUlSVKfvBhA4zbsVZa3AUe2gyRJkubRsM+yvIQpzhmrqj+a94gkSZKWmNk8y3LCJsDTga3mPxxJkqSlZ6iT+qvq2oHhZ1X1HuARI45NkiRpSRj2kOUDB95uQNNjtsVIIpIkSVpihj1k+a6B17cCq4BnzHs0kiRJS9CwV1nuO+pAJEmSlqphD1n+3UzTq+rw+QlHkiRp6ZnNVZYPBk5s3z8JOBW4bBRBSZIkLSXDJmTbAA+sqhsBkhwCfLqqXjiqwCRJkpaKYZ9luQvwm4H3vwGWzXs0kiRJS9CwPWQfBVYk+TzNHfufChw3sqgkSZKWkGGvsjw0yX8Cf9aOel5VfX90YUmSJC0dwx6yBLgDcENVvRdYneRuI4pJkiRpSRn2thdvprnScnfgaOB2wMeAh44uNEmSFpdlB3952mmrDnvCGCPRYjNsD9lTgScDvwSoqsvx0UmSJEnzYtiE7DdVVTQn9JNks9GFJEmStLQMm5CdkOTDwJ2TvAg4GThydGFJkiQtHes8hyxJgOOBewE30JxH9k9VddKIY5MkaUnw3DOtMyGrqkryhap6EGASJknSAmEit/4Y9pDld5M8eKSRSJIkLVHD3ql/X+AlSVbRXGkZms6z+40qMEmSNBr2rC08MyZkSXapqkuBx40pHkmSpCVnXT1kXwAeWFU/TfLZqvrLcQQlSZK0lKzrHLIMvP6jUQYiSZK0VK0rIatpXq9TkqOSXJ3k3IFxWyU5KclF7d8tB6a9PsnFSS5M8tjZ1CVJkrSYrSshu3+SG5LcCNyvfX1DkhuT3LCOsscA+00adzDwjaraDfhG+54kewAHAHu2ZT6YZMNZroskSdKiNGNCVlUbVtUdq2qLqtqofT3x/o7rKHsq8PNJo/cHjm1fHws8ZWD8p6rqlqq6BLgY2HvWayNJkrQIDXvbi/myXVVdAVBVVyS5Szt+R+C7A/Otbsf9gSQHAQcB7LLLLiMMVZIkDfJ2GaMz7I1hRy1TjJvynLWqOqKqllfV8m233XbEYUmSJI3euBOyq5JsD9D+vbodvxrYeWC+nYDLxxybJElSL8Z9yPJE4EDgsPbvFwfGfyLJ4cAOwG7AijHHJkmSRsBDnes2soQsySeBfYBtkqwG3kyTiJ2Q5AXApcDTAarqvCQnAOcDtwIvraq1o4pNkiRpIRlZQlZVz5pm0iOnmf9Q4NBRxSNJkrRQLZST+iVJkpYsEzJJkqSejfukfkmSpKEspYsBTMgkSdJ6pWsi12cC6CFLSZKkntlDJkmSNAfz0bNmD5kkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcmZJIkST0zIZMkSeqZCZkkSVLPTMgkSZJ6ZkImSZLUMxMySZKknpmQSZIk9cyETJIkqWcb9VFpklXAjcBa4NaqWp5kK+B4YBmwCnhGVV3XR3ySJEnj1GcP2b5VtVdVLW/fHwx8o6p2A77RvpckSVrvLaRDlvsDx7avjwWe0mMskiRJY9NXQlbA15N8L8lB7bjtquoKgPbvXaYqmOSgJCuTrFyzZs2YwpUkSRqdXs4hAx5aVZcnuQtwUpIfDVuwqo4AjgBYvnx5jSpASZKkcemlh6yqLm//Xg18HtgbuCrJ9gDt36v7iE2SJGncxp6QJdksyRYTr4HHAOcCJwIHtrMdCHxx3LFJkiT1oY9DltsBn08yUf8nquqrSc4ETkjyAuBS4Ok9xCZJkjR2Y0/IquonwP2nGH8t8MhxxyNJktS3hXTbC0mSpCXJhEySJKlnJmSSJEk9MyGTJEnqmQmZJElSz0zIJEmSemZCJkmS1DMTMkmSpJ6ZkEmSJPXMhEySJKlnJmSSJEk9MyGTJEnqmQmZJElSz0zIJEmSemZCJkmS1DMTMkmSpJ6ZkEmSJPXMhEySJKlnJmSSJEk9MyGTJEnqmQmZJElSz0zIJEmSemZCJkmS1DMTMkmSpJ6ZkEmSJPXMhEySJKlnJmSSJEk9MyGTJEnqmQmZJElSz0zIJEmSemZCJkmS1DMTMkmSpJ6ZkEmSJPXMhEySJKlnJmSSJEk9MyGTJEnqmQmZJElSz0zIJEmSemZCJkmS1DMTMkmSpJ6ZkEmSJPXMhEySJKlnJmSSJEk9MyGTJEnqmQmZJElSzxZcQpZkvyQXJrk4ycF9xyNJkjRqCyohS7Ih8AHgccAewLOS7NFvVJIkSaO1oBIyYG/g4qr6SVX9BvgUsH/PMUmSJI1UqqrvGP5XkqcB+1XVC9v3zwEeUlUvG5jnIOCg9u3uwIXTLG4b4JoOYVjOcpbrp9xiiNFylrPc4iu3kGLctaq2nXJKVS2YAXg68B8D758D/FvHZa20nOUst3jKLYYYLWc5yy2+coshxqpacIcsVwM7D7zfCbi8p1gkSZLGYqElZGcCuyW5W5LbAwcAJ/YckyRJ0kht1HcAg6rq1iQvA74GbAgcVVXndVzcEZaznOUWVbnFEKPlLGe5xVduMcS4sE7qlyRJWooW2iFLSZKkJceETJIkqWcmZJIkST0zIZMkSeqZCZmGkuQu4yizmCTZuu8Y1J3bb2qLpV3W9+8XLT3rfUKW5D9nmLY8ybeSfCzJzklOSvKLJGcmecAM5e6Y5F+SfDTJX02a9sEZyt01yb8n+UCSrZMckuScJCck2X6GcmcleVOSu69rfSeV22/g9Z2SfCTJD5N8Isl2M5TbatKwNbAiyZZJtpqvMgNlN0/yliTnte2/Jsl3kzx3Nus7sLxpt3nX+pIclmSb9vXyJD8Bzkjy0yQPn6HcndqyP0pybTtc0I678wzluu4rXffNrvtK189Q13bpWl/X7df1szfuz2ynz9Ac2mXc34Gdvl+67mczWdf3S5dyXdulYxydtt24zeGzMK/bPN06Izr9qFkvErIkD5xmeBCw1wxFPwi8A/gy8B3gw1V1J+Dgdtp0jgYCfBY4IMlnk2zcTvvjGcodA5wPXAZ8C7gZeALwX8CHZii3JXBn4FtJViR5dZIdZph/wtsGXr8LuAJ4Es0NeD88Q7lrgO8NDCuBHYGz2tfzVWbCx4GfAI8F/hl4H81js/ZN8rapCsxhm3eqD3hCVU08m+xfgWdW1T2AR9O07XROAK4D9qmqratqa2DfdtynZyh3DN32la77Ztd9petnqGu7dK2v6/br+tkb92e2yz4N3dtl3N+BXb9fOu1nXb9f5vC9dAwd2qVjIt51283lh0aXH1JdPwtdv1u6dkZ0+lEzpS7PW1poA7AW+CbNjjx5uHmGct8feH3pdNOmKHf2pPdvBP4b2Bo4q2N9Z89Q7qyB139G84/nynb9Dhqy3OSYZ6rv74GvAvcdGHfJOrbBrMsMzPeDSe/PbP9uAPxoPrf5HOr7EbBR+/q7k6adM0NdF3ac1nVf6bpvdt1Xun6GRtEuM9XXdfvNx2dvHJ/ZWe/Tc2yXcX8Hdvp+mcN+1vV/yij+F83ULl8EnkvzmMG/A/4R2A04FnjbfG67iTYH3glcCqwAXg3sMMR2WAE8DngWTdL5tHb8I4HT5/mz0Gmbt9Nva9dxcPht+/cn05Q5Z+D1t4AHt6/vySyfaTn0jAt5AM4Fdptm2mUzlDsdeAzNQ81/CjylHf/wmRoSuADYYNK4A4HzgJ/OUO4HA6/fOmnaD2co9wcfEponGewHHD1DudXth/Q1NL+eM0x97fSdaH5NHA5sMd3OONcybbnvAA9rXz8J+NrAtCk/QF23+RzqeznwdeARwCHAe4A/p+mN+OgMdX0deC2w3cC47YDXASePYF/pum922lfm8Bnq2i5d6+u6/bp+9sb6me2yT8+xXUbxHThtAthO7/Kd1HU/6/o/pWu5rp/3Lj8uO227yfs1s/uhMesfUnP4LHTa5u18XTojOv2omXJZs5l5oQ7A04Ddp5n2lBnK3Z/mMU3/CdwLeC9Nt+Z5wENnKPcO4FFTjN8PuGiGcm8BNp9i/D2Az8xQ7lMd2+XNk4Zt2/F3BY4bchlPAr4LXDmLep88mzLtdlgBXA+cBtyzHb8t8Ir53ObT1Lf7uuprp+8DHA98HzgH+ApwEHC7GcpsCby9/dBeB/yc5gvx7cBWI9hXuu6bnfaVaT5D17efoT+dRbtc17bLO9bRLnt1+cy2ZfedYvu9eB3br+tnb6yf2YF9+hez2afnsF+P9Ttw0rxDfyfN4fPX9X9K13JdP+9dflx22nbtPF1/aMz6h9QcPgudtvlA+Vkl/nT8UTPlsmYz80IegGBFN2UAAAVsSURBVL35XVfhHjSZ9eOHKPeQgXJ70mTjw5TrWt9iLHdf4E3DlBsovynw6VnM/5AucU5axlBJZjvvvYFHMelLENhvyDbpuq8MXW4u6zfOcm1bPnI2bTnNcmb15TUP5UbdLvfq0i5dyy2gOB836vra75f7zLZdaHp1XgM8ZpZt+bD2O2md5eZj+w1bH3A/Zvljdo7r1vWHRqcfbnPcBrP6fp9iGbNJ/Pdh6h81G82mndaLZ1kmeTPN8emNgJNo/rl/m2aDfK2qDh2y3N7AKR3Kda1vsZRbZ7skOXGKRT2C5nwKqurJU9XVNc4p6gtND8gw9b0C+FuaX1B7Aa+sqi+2086qqgcOEWPXfWXYcp3Wbx7LwRDbr0tbzrG+vssN254vB15G88t8Nu3Stdxctt9Lxxhn13Jd41xRVXu3r1/YLuMLNL01X6qqw4Yo96K23OeHKDcfcQ5d30ySPK+qjh5HXTPVN09xvpBmvxnZNphmWZsCd6+qc7us36zLdMl2F9pAk5FuCNwBuAG4Yzt+U2Y+1my5eSpHc7XTx2h+KTy8/XtF+/rh8739aH6JzKW+zdvXy2iu0nrlxHL7bsu5rF8P5WbdlnPZX+YQ57jr69ouXcstljjH3i4Dr8/kd4e9NmPmixa6lhtrnDMNTDpXa5R1zVTfuOPsug1GsX6zLbMR64dbq2ot8KskP66qGwCq6uYkt1luLOWWA6+kuWLnH6rq7CQ3V9UpM9Qzl/oeNIf6Nqyqm9o6ViXZB/hMkl1pekDmK8a5lOu6fuMu16Utofv+0jXOcdfXtV26llsscY673AZJtqQ5yT1VtaZdxi+T3DqCcmONM8kPp5tEcyL7fK5b1/rGHWfXbdApzq5tMqWu2eJCGoAzgDu0rzcYGH8nZr4E23LzWK6dZ+KEyPcz5K+DHur7JrDXpHEbAccBaxdKW3Zdv3GW69KWi2n9xt0u427PccfZQ7lVNFfoXdL+vWs7fnNmvnVC13LjjvMqmsNyu04algGXz2ddXesbd5xz+Qx1jLNTm0y5rNnMvFAHYONpxm/DwOWrlhttuUnzPoFp7oOzAOrbaeLDPcW0Ka/U67MtZ7t+4yzXpS0X0/qNu13G3Z7jjrPvdhkocwfgbvNdbtxxAh+hvcpyimmfmO826VrfOOOcyzboEud8rtt6cVK/JEnSYrZePDpJkiRpMTMhkyRJ6pkJmaRFLcnWSc5uhyuT/Gzg/e0nzbsq7YOA57H+bydZPrD8c9rh/CRvze8e3CxJ01pfbnshaYmqqmtprnIiySHATVX1zh5D2reqrkmyOXBEOxzYYzySFgF7yCStd5I8Msn3256qoyb3UiXZNMlXk7woyWbtPGe2ZfZv53luks+1812U5B2ziaGaeyG9BHhKkq3mb+0krY9MyCStbzYBjgGeWVX3pTkS8H8Gpm8OfInmkvQjaW6m+s2qejDNY5H+Nclm7bx7Ac+keZ7rM5PsPJtAqrkR8CXAbt1XR9JSYEImaX2zIXBJVf1P+/5Y4M8Hpn8ROLqqjmvfPwY4OMnZNM9Q3QTYpZ32jar6RVX9Gjif5oaPszXj3cElCUzIJK1/frmO6f8NPC7JRKIU4C+raq922KWqLmin3TJQbi2zPO82yRY0d+z+n3XMKmmJMyGTtL7ZBFiW5B7t++cAg890/CfgWuCD7fuvAS+fSNCSPGA+gmhP6v8g8IWqum4+lilp/WVCJml982vgecCnk5wD3AZ8aNI8rwI2aU/U/7/A7YAfJjm3fT8X32qXswK4FHjxHJcnaQnw0UmSJEk9s4dMkiSpZyZkkiRJPTMhkyRJ6pkJmSRJUs9MyCRJknpmQiZJktQzEzJJkqSe/X+jsG4CYbdRJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.set_title(\"Frequency of Tokens in the whole Dataset\")\n",
    "ax.set_xlabel(\"Token ID\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "pd.Series(lens).value_counts().head(40).plot(kind=\"bar\");\n",
    "print(\"text length mean: \", np.array(lens).mean())\n",
    "print(\"text length median: \", np.median(lens))\n",
    "print(\"text length standard deviation: \", np.array(lens).std())\n",
    "print(\"suitable sequence length: \", np.array(lens).mean() + 2*np.array(lens).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will truncate texts to a suitable sequence length of 62\n",
    "sequence_length = 62\n",
    "# X_train_tokens[i] := sequence of sequence_length many tokens that represent text_{i}\n",
    "X_train_tokens = []\n",
    "\n",
    "for text in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(text,\n",
    "                                         add_special_tokens=True, # special tokens for BERT\n",
    "                                         max_length=sequence_length,\n",
    "                                         padding=\"max_length\",\n",
    "                                         return_tensors='pt', # pytorch tensor format\n",
    "                                         truncation=True)\n",
    "    X_train_tokens.append(encoded_dict['input_ids'])\n",
    "\n",
    "# Pytorch expects tensors\n",
    "X_train_tokens = torch.cat(X_train_tokens, dim=0) # concat into one tensor\n",
    "y_train = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Tokenization:\n",
      " tensor([  101,  1412, 19301,  1132,  1103,  2255,  1104,  1142,   108,  8386,\n",
      "         1336,  1155,  3354, 10737,  1366,  1155,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the first obs tokenized\n",
    "print('Original:\\n', X_train[0])\n",
    "print('Tokenization:\\n', X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader is used to serve the data up in batchesta\n",
    "#for more on DataLoader: https://www.journaldev.com/36576/pytorch-dataloader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#split into training/validation\n",
    "dataset = TensorDataset(X_train_tokens, y_train.float())\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_set,\n",
    "                             sampler = RandomSampler(train_set),\n",
    "                             batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(val_set,\n",
    "                                  sampler = RandomSampler(val_set),\n",
    "                                  batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "first entry:  torch.Size([32, 62]) <class 'torch.Tensor'> torch.int64\n",
      "\n",
      "second entry:  torch.Size([32]) <class 'torch.Tensor'> torch.float32\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(\"\\nfirst entry: \", batch[0].size(), type(batch[0]), batch[0].dtype)\n",
    "    print(\"\\nsecond entry: \", batch[1].size(), type(batch[1]), batch[1].dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  137,  172,  ...,    0,    0,    0],\n",
       "        [ 101, 3885,  170,  ...,    0,    0,    0],\n",
       "        [ 101, 1103, 1614,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1136,  119,  ...,    0,    0,    0],\n",
       "        [ 101, 3304, 8966,  ...,    0,    0,    0],\n",
       "        [ 101, 1103, 1248,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0] #tokens (dim: batch size x features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1] #class labels of each observation in the batch (dim: batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3015c5bb9471cae0ec8ecaa493eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29e97ab280e4aac88e752640393ee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert output:  <class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'> 2\n",
      "first entry:  <class 'torch.Tensor'> torch.Size([32, 62, 768])\n",
      "second entry:  <class 'torch.Tensor'> torch.Size([32, 768])\n"
     ]
    }
   ],
   "source": [
    "#good tutorial on BERT\n",
    "#https://www.youtube.com/watch?v=xI0HHN5XKDo\n",
    "#BERT -> creates a feature representation from the text sequences\n",
    "\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert.to(device)\n",
    "\n",
    "for batch in train_dataloader: \n",
    "    batch_features = batch[0].to(device)\n",
    "    bert_output = bert(input_ids=batch_features) \n",
    "    print(\"bert output: \", type(bert_output), len(bert_output))\n",
    "    print(\"first entry: \", type(bert_output[0]), bert_output[0].size())\n",
    "    print(\"second entry: \", type(bert_output[1]), bert_output[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first entry: contains representation of each token in each sequence of the batch (dim: batch_size x sequence length x 768)\n",
    "#second entry: contains pooled representation of the whole sequence per obs in the batch (dim: batch_size x 768)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') # returns pwerful representations of the microblogs\n",
    "        self.linear = nn.Linear(768, 1) # custom layer; input of the first custom layer has to match the dimensionality of the BERT-output\n",
    "        self.sigmoid = nn.Sigmoid() # activation function applied to our custom layer to obtain probabilities\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        bert_output = self.bert(input_ids=tokens)\n",
    "        linear_output = self.linear(bert_output[1])\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model and evaluate\n",
    "def eval(y_batch, probas):\n",
    "    preds_batch_np = np.round(probas.cpu().detach().numpy())\n",
    "    y_batch_np = y_batch.cpu().detach().numpy()\n",
    "    acc = accuracy_score(y_true=y_batch_np, y_pred=preds_batch_np)\n",
    "    f1 = f1_score(y_true=y_batch_np, y_pred=preds_batch_np, average='weighted')\n",
    "    return acc, f1\n",
    "\n",
    "    \n",
    "\n",
    "def train(model, optimizer, scheduler, epochs, name):\n",
    "    history = []\n",
    "    best_f1 = 0\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # ===== train =====\n",
    "        print(\"=== Epoch: \", epoch+1, \" / \", epochs, \" ===\")\n",
    "        acc_total = 0\n",
    "        f1_total = 0\n",
    "        for it, batch in enumerate(train_dataloader): \n",
    "            x_batch, y_batch = [batch[0].to(device), batch[1].to(device)] # draw the batch\n",
    "            probas = torch.flatten(model(tokens=x_batch))\n",
    "            acc_f1_batch = eval(y_batch, probas)\n",
    "            acc_total, f1_total = acc_total + acc_f1_batch[0], f1_total + acc_f1_batch[1]\n",
    "            model.zero_grad() # reset the gradients\n",
    "            loss_func = nn.BCELoss()\n",
    "            batch_loss = loss_func(probas, y_batch)\n",
    "            batch_loss.backward() # calculate gradient per (learnable) weight\n",
    "            optimizer.step() # update (learnable) weights\n",
    "            scheduler.step() # update learning rate\n",
    "        acc_total = acc_total/len(train_dataloader) #len(train dataloader)=num_batches\n",
    "        f1_total = f1_total/len(train_dataloader)\n",
    "        print(\"accuracy: \", acc_total, \"\\nf1: \", f1_total)\n",
    "\n",
    "        # ===== validate =====\n",
    "        acc_val_total = 0\n",
    "        f1_val_total = 0\n",
    "        for batch in validation_dataloader:\n",
    "            x_batch, y_batch = [batch[0].to(device), batch[1].to(device)]\n",
    "            with torch.no_grad(): # gradients don't have to be computed, because no update is performed\n",
    "                probas = torch.flatten(model(tokens=x_batch))\n",
    "            acc_f1_val_batch = eval(y_batch, probas)\n",
    "            acc_val_total, f1_val_total = acc_val_total + acc_f1_val_batch[0], f1_val_total + acc_f1_val_batch[1]\n",
    "        acc_val_total = acc_val_total/len(validation_dataloader)\n",
    "        f1_val_total = f1_val_total/len(validation_dataloader)\n",
    "        print(\"validation accuracy: \", acc_val_total, \"\\nvalidation f1: \", f1_val_total, \"\\n\")\n",
    "        if(f1_val_total>best_f1): # save current mdoel if this epoch improved models validation performance \n",
    "            torch.save(model, name+\".pt\")\n",
    "            best_f1 = f1_val_total\n",
    "\n",
    "        history.append({\"acc\":acc_total, \"f1\":f1_total, \"acc_val\":acc_val_total, \"f1_val\":f1_val_total})\n",
    "    return [torch.load(name+\".pt\"), history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch:  1  /  5  ===\n",
      "accuracy:  0.606119109947644 \n",
      "f1:  0.5663419054834833\n",
      "validation accuracy:  0.6785567434210527 \n",
      "validation f1:  0.6770071938811136 \n",
      "\n",
      "=== Epoch:  2  /  5  ===\n",
      "accuracy:  0.700818062827225 \n",
      "f1:  0.6858985218590077\n",
      "validation accuracy:  0.7234443530701754 \n",
      "validation f1:  0.7078973277376331 \n",
      "\n",
      "=== Epoch:  3  /  5  ===\n",
      "accuracy:  0.7824934554973823 \n",
      "f1:  0.7775888851479842\n",
      "validation accuracy:  0.744311951754386 \n",
      "validation f1:  0.734984574628315 \n",
      "\n",
      "=== Epoch:  4  /  5  ===\n",
      "accuracy:  0.855791884816754 \n",
      "f1:  0.8530402705945934\n",
      "validation accuracy:  0.7601425438596491 \n",
      "validation f1:  0.7565993635223635 \n",
      "\n",
      "=== Epoch:  5  /  5  ===\n",
      "accuracy:  0.8982329842931938 \n",
      "f1:  0.8971015599854455\n",
      "validation accuracy:  0.746265076754386 \n",
      "validation f1:  0.7470446092189859 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "baseline_bert_clf = BertClassifier()\n",
    "baseline_bert_clf = baseline_bert_clf.to(device)\n",
    "adam = AdamW(baseline_bert_clf.parameters(), lr=2e-5, eps=1e-8)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "sched = get_linear_schedule_with_warmup(adam, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "baseline_bert_clf, history = train(model=baseline_bert_clf, optimizer=adam, scheduler=sched, epochs=5, name=\"baseline_bert_clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analogously to above:\n",
    "X_test = pd.read_csv(\"test.csv\")[\"text\"]\n",
    "\n",
    "\n",
    "X_test_tokens = []\n",
    "for text in X_test:\n",
    "    encoded_dict = tokenizer.encode_plus(text,\n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=sequence_length,\n",
    "                                         padding=\"max_length\",\n",
    "                                         return_tensors='pt',\n",
    "                                         truncation=True)\n",
    "    X_test_tokens.append(encoded_dict['input_ids'])\n",
    "X_test_tokens = torch.cat(X_test_tokens, dim=0)\n",
    "\n",
    "test_set = TensorDataset(X_test_tokens)\n",
    "test_dataloader = DataLoader(test_set, \n",
    "                             sampler=SequentialSampler(test_set), \n",
    "                             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    x_batch = batch[0].to(device)\n",
    "    with torch.no_grad():\n",
    "        probas = baseline_bert_clf(tokens=x_batch)\n",
    "    preds = np.round(probas.cpu().detach().numpy()).astype(int).flatten()\n",
    "    all_preds.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_pred = pd.concat([pd.read_csv(\"sample_submission.csv\")[\"id\"], pd.Series(all_preds)], axis=1)\n",
    "challenge_pred.columns = ['id', 'target']\n",
    "challenge_pred.to_csv(\"submission_bert.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
